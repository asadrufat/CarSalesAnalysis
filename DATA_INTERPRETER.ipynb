{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DATA INTERPRETER\n",
    "This Jupyter notebook is used to visualize and interpret the processed data. In other words, we will conduct the analysis on the sample distribution of car sales in the Czech republic through a bar chart and a heatmap. Moreover, the analysis will go on with a Machine Learning model which first splits the data into sets of data for training and testing, then predicts prices for cars for which the user can insert input details ranging from year to mileage to location (region this time). \n",
    "\n",
    "But we first need to continue processing the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import of packages\n",
    "Numpy, Plotly, pandas and json packages will be used in the first part of this Jupyter notebook in order to combine and process the datasets. For visualisation Plotly will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('merged_car_data.csv', ',')\n",
    "df2 = pd.read_csv('data_okresy.csv', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data = pd.concat([df1, df2], axis = 1)\n",
    "big_data = big_data.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the geojson file containing data on the geographical coordinates of the Czech districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "czech_regions = json.load(open(\"distictsCzechiaLow.json\", encoding = \"UTF-8\"))\n",
    "#czech_regions['features'][0]['properties']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we need to do is matching coordinates from the json file with the districts in our merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_id_map = {}\n",
    "for feature in czech_regions[\"features\"]:\n",
    "    feature[\"id\"] = feature[\"properties\"][\"id\"]\n",
    "    state_id_map[feature[\"properties\"][\"name\"]] = feature[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['All Okresy', 'id'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_id_map\n",
    "mapping = pd.DataFrame([state_id_map]).T\n",
    "mapping.columns = ['id']\n",
    "mapping = mapping.reset_index().rename(columns = {'index': 'All Okresy'})\n",
    "mapping.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigDataGrouped = big_data.groupby(['Okres']).size().reset_index(name='counts')\n",
    "new = bigDataGrouped[\"Okres\"].str.split(\"\\n \", n = 1, expand = True)\n",
    "bigDataGrouped[\"Okres\"] = new[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the below script makes a slight change in names of some districts in our initial dataset for perfect matching. Using the method .groupby(), we are able to see how many cars there are in each Czech district. For the districts that are not available in this dataset but available in the geojson file, we will aoutomatically assign 0 amount of cars with the codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigFinal = bigDataGrouped.groupby(['Okres'], as_index=False).sum()\n",
    "bigFinal.Okres.replace({\n",
    "    'Hlavní město Praha':'Praha',\n",
    "    'Rychnov nad Kněžnou':'Rychnov n.K.',\n",
    "    'Ústí nad Orlicí':'Ústí n.O.',\n",
    "    'Žďár nad Sázavou':'Žďár n.S.'\n",
    "    },\n",
    "    inplace = True\n",
    ")\n",
    "bigFinal['id'] = bigFinal['Okres'].apply(lambda x: state_id_map[x])\n",
    "#bigFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigFinal\n",
    "mapping.id\n",
    "allFinal = bigFinal.merge(mapping, on = 'id', how = 'right').replace(np.nan, 0).drop(columns = 'Okres')\n",
    "#allFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have put two options for the interactive map; the second is more vivid, in our opinions :)\n",
    "\n",
    "P.S. Please drag it to Europe in the monitor, so you can view territory of the Czech Republic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.choropleth(allFinal, locations = 'id', geojson = czech_regions, color = 'counts', hover_data=[\"counts\"])\n",
    "#fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The map will be opened in your browser for not putting too much \"pressure\" on the Jupyter Notebook\n",
    "\n",
    "fig2 = px.choropleth_mapbox(\n",
    "    allFinal,\n",
    "    locations=\"id\",\n",
    "    geojson=czech_regions,\n",
    "    color=\"counts\",\n",
    "    hover_name=\"All Okresy\",\n",
    "    hover_data=[\"counts\"],\n",
    "    title=\"Car Sales per District\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 50, \"lon\": 15},\n",
    "    zoom=6,\n",
    "    opacity=0.7,\n",
    ")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bar Chart\n",
    "\n",
    "Now we will import necessary packages, most importantly from bokeh, in order to construct an illuminating bar chart that shows the distribution of 53 different car brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, curdoc\n",
    "from bokeh.palettes import plasma, turbo\n",
    "from bokeh.layouts import row, column\n",
    "from collections import Counter\n",
    "\n",
    "car_brands = df1['Name'].str.split(\" \", n = 1, expand = True)[0]\n",
    "brand_names = Counter(car_brands).keys()\n",
    "brand_frequency = Counter(car_brands).values()\n",
    "brand_names = list(brand_names)\n",
    "brand_frequency = list(brand_frequency)\n",
    "sorted_brands = sorted(brand_names, key=lambda x: brand_frequency[brand_names.index(x)])\n",
    "\n",
    "\n",
    "p2 = figure(title = \"Distribution of Brands in car sales in Czechia (simple plot)\",\n",
    "            x_range = sorted_brands,\n",
    "            plot_height=660,\n",
    "            plot_width = 980,\n",
    "            toolbar_location = None)\n",
    "\n",
    "p2.vbar(x = brand_names, \n",
    "        top= brand_frequency, \n",
    "        width = 0.9,\n",
    "        color = plasma(53))\n",
    "\n",
    "#Getting rid of gridlines of x axis\n",
    "p2.xgrid.grid_line_color = None\n",
    "\n",
    "#Starting the y axis from 500 rather than 0\n",
    "p2.y_range.start = 0\n",
    "\n",
    "#Rotating labels such that they do not overlap\n",
    "p2.xaxis.major_label_orientation = 1\n",
    "\n",
    "#Adding y axis label\n",
    "p2.yaxis.axis_label = 'Number of sales per one brand'\n",
    "\n",
    "#Display the bar chart\n",
    "show(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Next part with Machine Learning model\n",
    "\n",
    "We will know import necessary stuff from the Scikit-learn library of Python in order to create a nice Linear Regression. But we first need to clean the data as the numbers such as mileages and prices are still string type of parameters in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the price column from initial dataset as we are going to predict prices for cars. Also, we will trim the Name column for creating a nicer column called Brand, which is way more useful for prediction. We will also drop the Obec column as we will use Regions for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Brand'] = df1['Name'].str.split(\" \", n = 1, expand = True)[0]\n",
    "df1.Year = df1.Year.apply(lambda x: pd.to_numeric(x))\n",
    "df1 = df1.dropna()\n",
    "y = df1.Price\n",
    "x = df1.drop(['Price', 'Name', 'Obec'], axis=1)\n",
    "x.Mileage = x.Mileage.str.split(\"km\", n = 1, expand = True)[0]\n",
    "y = y.str.split('Kč', n = 1, expand = True)[0]\n",
    "x = x.reset_index().drop(columns = ['index'])\n",
    "y = y.reset_index().drop(columns = 'index')\n",
    "y.columns = ['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are cleaning the data about Price and Mileage by converting them into integers, just as they still carry some string values that we do not like, despite we used \"utf-8\" in scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "intPrice = []\n",
    "intMileage = []\n",
    "for i in y.Price:\n",
    "    intPrice.append(int(i.replace(u'\\xa0', u'')))\n",
    "for j in x.Mileage:\n",
    "    intMileage.append(int(j.replace(u'\\xa0', u'')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the column Engine, we can simplify things by creating two categorical variables \"Benzin\" and \"Nafta\". Thus, we do not really need to complicate things with dozens of Engine types with numerical Kilowatts. Also, since the column Body contains values such as \"Suv\", \"suV\", and \"SUV\", we will convert all values to lowercase versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    x['Engine'].str.contains('Benzín'),\n",
    "    x['Engine'].str.contains('Nafta')]\n",
    "    \n",
    "values = ['Benzín', 'Nafta']\n",
    "\n",
    "x['Engine'] = np.select(conditions, values)\n",
    "x['Body'] = x.Body.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finish the data processing and create the dummy variables and then split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.Mileage = intMileage\n",
    "y.Price = intPrice\n",
    "x.Year = x.Year.astype(int)\n",
    "dummy = pd.get_dummies(x, drop_first = True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "dummyCols = dummy.columns.tolist()\n",
    "X = dummy\n",
    "X = X.drop(columns = ['Location_NEJNIŽŠÍ MOŽNÉ SPLÁTKY NA ÚVĚRY!!!', \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35115.25198611],\n",
       "       [181304.26675663],\n",
       "       [267545.59954252],\n",
       "       ...,\n",
       "       [167316.51033074],\n",
       "       [212849.76193966],\n",
       "       [ 60860.64780837]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediction =  LR.predict(X_test)\n",
    "y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are importing additional packages for CrossValidation and showing the R^2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score is 0.5225459907781258\n"
     ]
    }
   ],
   "source": [
    "score=r2_score(y_test,y_prediction)\n",
    "print(f'r2 score is {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above value, the model is not at its best, but not the worst either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51672341,  0.56509751,  0.46571261,  0.57356568,  0.55438765,\n",
       "        0.44193563, -2.33253819,  0.58201809,  0.45167843,  0.49158461])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "scores = cross_val_score(LR, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us define a function which will help the users to predict price of cars of their own interest by inserting 7 input values, ranging from year to mileage to body to brand. Note that for prediction we create another dataframe which is then put into the ML model. Thus we first initialize all values with zeros, then the function converts input values to prediction values itself. Mind that, for a body type, for instance, if the user inserts input as \"SUV\", the function assigns the value 1 to the dummy variable \"Body_suv\", while others still have 0. User can convert all assigned values to zeros using the single line of code after the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCols = X.columns.tolist()\n",
    "Values = np.zeros(len(allCols))\n",
    "carPredict = pd.DataFrame(Values, allCols).T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, in a simple regression model, if we have K categorical variables, we will use K-1 dummy variables within the model (except for some models such as Decision Trees). Thus, the model below drops some variables and that is why we include if-else statements below in order to make sure that the model can read whenever putting an input of a dropped variable into the model. In other words, if the user inserts brand \"Alfa\", which is dropped from the dummy variables, the model will automatically assign zeros to the rest of the dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[449540.42324271]]\n"
     ]
    }
   ],
   "source": [
    "def addPredictingParameters(year, mileage, engine, gearbox, body, location, brand):   \n",
    "    carPredict['Year'][0] = year\n",
    "    carPredict['Mileage'][0] = mileage\n",
    "    \n",
    "    if 'Engine_' + str(engine) in allCols:\n",
    "        carPredict['Engine_' + str(engine)][0] = 1\n",
    "    else:\n",
    "        contains_engine = [col for col in carPredict.columns if 'Engine_' in col]\n",
    "        carPredict[contains_engine] = 0\n",
    "    \n",
    "    if 'Gearbox_' + str(gearbox) in allCols:\n",
    "        carPredict['Gearbox_' + str(gearbox)][0] = 1\n",
    "    else:\n",
    "        contains_gearbox = [col for col in carPredict.columns if 'Gearbox_' in col]\n",
    "        carPredict[contains_gearbox] = 0\n",
    "        \n",
    "    if 'Body_' + str(body) in allCols:\n",
    "        carPredict['Body_' + str(body)][0] = 1\n",
    "    else:\n",
    "        contains_body = [col for col in carPredict.columns if 'Body_' in col]\n",
    "        carPredict[contains_body] = 0\n",
    "        \n",
    "    if 'Location_' + str(location) in allCols:\n",
    "        carPredict['Location_' + str(location)][0] = 1\n",
    "    else:\n",
    "        contains_location = [col for col in carPredict.columns if 'Location_' in col]\n",
    "        carPredict[contains_location] = 0\n",
    "        \n",
    "    if 'Brand_' + str(brand) in allCols:\n",
    "        carPredict['Brand_' + str(brand)][0] = 1\n",
    "    else:\n",
    "        contains_brand = [col for col in carPredict.columns if 'Brand_' in col]\n",
    "        carPredict[contains_brand] = 0        \n",
    "        \n",
    "        \n",
    "addPredictingParameters(2006, 220000, 'Benzín', 'Automatická', 'sedan', 'Praha', 'Mercedes-Benz')\n",
    "print(LR.predict(carPredict))\n",
    "carPredict = pd.DataFrame(pd.Series(0, index=carPredict.columns)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Basic Interpretations\n",
    "\n",
    "The visualization derived from the interactive map suggests that in a sample of 6000 car, most of them (or roughly 709) are available in Prague (Praha). Furthermore, there comes other prominent cities such as Brno, Plzen, Karlovy-vary, and Ceske Budejovice. Actually, this makes sense since those cities are concentrated with more people who naturally perform higher number of sales.\n",
    "\n",
    "When it comes to the bar chart depicting brand distribution within our sample, the data show that Skoda is the most frequently represented car brand with a number of 990 cars. Skoda is then followed by other famous brands like Volkswagen, Ford, Renault, Mercedes, Audi and so on. The least represented brand was Infinity and some other US-based firms. The results give us a bit clearer insight about geographical and sosioeconomic tastes of people in the Czech Republic.\n",
    "\n",
    "Lastly, speaking of the pricing model, it returns higher prices for newer cars, which is quite intuitive and thus in line with reality. Also, cars that are in sale in bigger cities are more expensive. Likewise, cars with the automatic gearbox are following the same pattern too. Last but not least, cars with a great record of mileage are less expensive as expected. \n",
    "\n",
    "Note that some of this results cannot be interpreted for whole car industry and market in the Czech Republic. It is nothing but a mere interpretation of ours derived from a sample of 6000 cars from the given website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
